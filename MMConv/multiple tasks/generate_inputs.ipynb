{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboardX'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load, load_all, save\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read, list2dict\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zhiyi\\Desktop\\NLC\\project\\MMConv\\multiple tasks\\utils\\__init__.py:3\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboardX\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboardX'"
     ]
    }
   ],
   "source": [
    "from utils.json_utils import load, load_all, save\n",
    "from utils.generic_utils import read, list2dict\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "path = \"../dataset/\"\n",
    "with open(path + \"dialogues.json\") as f:\n",
    "        dialogues = json.load(f)\n",
    "        \n",
    "data = load(path + 'evidence_for_delex.json')\n",
    "data_dict = list2dict(data, 'dialogue_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slot_info(slot):\n",
    "    info = slot.split(': ')\n",
    "    return (info[0].strip(), None) if len(info) == 1 else (info[0].strip(), info[1].strip())\n",
    "\n",
    "turn_label_key = {\n",
    "    'agent': 'dialog_act',\n",
    "    'user': 'turn_label'\n",
    "}\n",
    "\n",
    "correct_value = {\n",
    "    'yes (incl. american express & mastercard)': 'yes',\n",
    "    'yes (incl. american express)': 'yes',\n",
    "    'yes (incl. nfc payments & mastercard)': 'yes',\n",
    "    'yes (incl. nfc payments & visa)': 'yes',\n",
    "    'yes (incl. visa & american express)': 'yes',\n",
    "    'yes (incl. visa & mastercard)': 'yes',\n",
    "    'cocktail': 'cocktails',\n",
    "    'modearte': 'moderate',\n",
    "    'free & paid': 'yes',\n",
    "    'desserts': 'dessert',\n",
    "    'sessert': 'dessert',\n",
    "    'free & paid': 'yes',\n",
    "    'goos': 'good',\n",
    "    'bar snacks': 'bar snack'\n",
    "}\n",
    "\n",
    "def extract_slot(slot):\n",
    "    slot_conv = {\n",
    "        'menu': 'menus',\n",
    "        'drink': 'drinks',\n",
    "        'musics': 'music',\n",
    "        'reservation': 'reservations',\n",
    "        'credit card': 'credit cards',\n",
    "        'outdoor seatings': 'outdoor seating',\n",
    "        'dining option': 'dining options',\n",
    "        'wifi': 'wi-fi'\n",
    "    }\n",
    "    slot_name, value = slot_info(slot)\n",
    "    slot_name = slot_name.lower()\n",
    "    if slot_name in slot_conv:\n",
    "        slot_name = slot_conv[slot_name]\n",
    "    if value is not None:\n",
    "        value = value.lower()\n",
    "        if value in correct_value:\n",
    "            value = correct_value[value]\n",
    "        if slot_name == 'wi-fi' and value in ('free', 'paid', 'good'):\n",
    "            value = 'yes'\n",
    "        if value.replace(' ', '') in ('dontcare', 'don\\'tcare', 'donotcare', 'doesnotcare', 'doesntcare', 'doesn\\'tcare'):\n",
    "            value = 'dontcare'\n",
    "    return slot_name, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/ontology.json...\n",
      "Loaded ../dataset/ontology.json to <class 'dict'> object\n"
     ]
    }
   ],
   "source": [
    "slot_opts = load( path +'ontology.json')\n",
    "\n",
    "slot_name_map = {slot_name.lower(): slot_name for slot_name in slot_opts}\n",
    "\n",
    "wrong_slots = {'delivery',}\n",
    "\n",
    "telephone_matcher = re.compile('(65|65 |[+]65|[+]65 )?\\d{4} ?\\d{4}')\n",
    "\n",
    "\n",
    "def get_candidate_value(slots):\n",
    "    for slot_name, slot_info in slots.values():\n",
    "        slot_name = slot_name.lower()\n",
    "        slot_info\n",
    "\n",
    "        \n",
    "def delex_slot(transcript, slot, exclude_slots=set(), evidences={}):\n",
    "    def dist(span1, span2):\n",
    "        return min(abs(span1[0] - span2[1]), abs(span1[1] - span2[0]))\n",
    "\n",
    "    def find_and_replace(transcript, value):\n",
    "        value_padded = ' ' + value\n",
    "        transcript_padded = ' ' + transcript\n",
    "        transcript_list = []\n",
    "        replace_with = f'[{name}]'\n",
    "        last_idx = -1\n",
    "        while True:\n",
    "            if last_idx != -1:\n",
    "                if last_idx + len(value_padded) >= len(transcript_padded):\n",
    "                    break\n",
    "                to_search = transcript_padded[last_idx + len(value_padded)]\n",
    "            else:\n",
    "                to_search = transcript_padded\n",
    "            match_idx = to_search.find(value_padded)\n",
    "            if match_idx != -1:\n",
    "                if match_idx + len(value_padded) < len(transcript_padded) and transcript_padded[match_idx + len(value_padded)].isalnum():\n",
    "                    last_idx = match_idx\n",
    "                    continue\n",
    "                if last_idx != -1:\n",
    "                    match_idx += last_idx\n",
    "                transcript_list.append(transcript[:match_idx])\n",
    "                transcript_list.append(replace_with)\n",
    "                last_idx = match_idx\n",
    "            else:\n",
    "                break\n",
    "        if last_idx != -1:\n",
    "            transcript_list.append(transcript[last_idx + len(value_padded) - 1:])\n",
    "        if transcript_list:\n",
    "            return ''.join(transcript_list), True\n",
    "        return transcript, False\n",
    "\n",
    "    name, value = extract_slot(slot)\n",
    "    if name not in exclude_slots and name not in wrong_slots and value is not None:\n",
    "        if slot_opts[slot_name_map[name.lower()]]['type'] == 'yes/no':\n",
    "            transcript_lower = transcript.lower()\n",
    "            matches = list(re.finditer(f'(^| ){value}($|[.,;! ])', transcript_lower))\n",
    "            if matches:\n",
    "                keyword_idx = transcript_lower.find(name)\n",
    "                if keyword_idx == -1:\n",
    "                    for kw in slot_opts[slot_name_map[name.lower()]]['keywords']:\n",
    "                        keyword_idx = transcript_lower.find(kw)\n",
    "                        if keyword_idx != -1:\n",
    "                            keyword = kw\n",
    "                            break\n",
    "                else:\n",
    "                    keyword = name\n",
    "                if keyword_idx != -1:\n",
    "                    first_span = matches[0].span()\n",
    "                    kw_span = (keyword_idx, keyword_idx + len(keyword))\n",
    "                    min_dist = [0, dist(first_span, kw_span)]\n",
    "                    for i, match in enumerate(matches):\n",
    "                        curr_dist = dist(match.span(), kw_span)\n",
    "                        if curr_dist < min_dist[1]:\n",
    "                            min_dist = [i, curr_dist]\n",
    "                    min_span = matches[min_dist[0]].span()\n",
    "                    t_match = matches[min_dist[0]].group(0)\n",
    "                    if t_match[0].isalpha():\n",
    "                        offset_begin = 0\n",
    "                    else:\n",
    "                        offset_begin = 1\n",
    "                    if t_match[-1].isalpha():\n",
    "                        offset_end = 0\n",
    "                    else:\n",
    "                        offset_end = 1\n",
    "                    return transcript[:min_span[0] + offset_begin] + f'[{name}]' + transcript[min_span[1] - offset_end:]\n",
    "                else:\n",
    "                    transcript_list = []\n",
    "                    if matches[0].group(0)[0].isalpha():\n",
    "                        offset_begin = 0\n",
    "                    else:\n",
    "                        offset_begin = 1\n",
    "                    transcript_list.append(transcript[:matches[0].start() + offset_begin])\n",
    "                    replace_with = f'[{name}]'\n",
    "                    for i, match in enumerate(matches):\n",
    "                        transcript_list.append(replace_with)\n",
    "                        if i < len(matches) - 1:\n",
    "                            if match.group(0)[-1].isalpha():\n",
    "                                offset_end = 0\n",
    "                            else:\n",
    "                                offset_end = 1\n",
    "                            if matches[i + 1].group(0)[0].isalpha():\n",
    "                                offset_begin = 0\n",
    "                            else:\n",
    "                                offset_begin = 1\n",
    "                            transcript_list.append(transcript[match.end() - offset_end: matches[i + 1].start() + offset_begin])\n",
    "                    if matches[-1].group(0)[-1].isalpha():\n",
    "                        offset_end = 0\n",
    "                    else:\n",
    "                        offset_end = 1\n",
    "                    transcript_list.append(transcript[matches[-1].end() - offset_end:])\n",
    "                    return ''.join(transcript_list)\n",
    "            else:\n",
    "                return transcript\n",
    "        else:\n",
    "            value = slot.split(': ')[1]\n",
    "            if name == 'telephone':\n",
    "                transcipt = telephone_matcher.sub('[telephone]', transcript)\n",
    "                value = telephone_matcher.sub('[telephone]', value)\n",
    "            else:\n",
    "                result = False\n",
    "                candidates = [value, value.lower()]\n",
    "                if name in evidences:\n",
    "                    evidence = evidences[name]\n",
    "                    if evidence:\n",
    "                        if isinstance(evidence, str):\n",
    "                            evidence = [evidence]\n",
    "                        for e in evidence:\n",
    "                            if e:\n",
    "                                candidates.extend([e, e.lower()])\n",
    "                for candidate in candidates:\n",
    "                    if not result:\n",
    "                        transcript, result = find_and_replace(transcript, candidate)\n",
    "                    else:\n",
    "                        break\n",
    "            return transcript\n",
    "    return transcript\n",
    "\n",
    "\n",
    "def do_delex(dialogue, turn_idx, role='agent', exclude_slots=set()):\n",
    "    def sort_slot(sa):\n",
    "        if sa[0] == 'venueaddress':\n",
    "            return 0\n",
    "        if sa[0] == 'venuename':\n",
    "            return 1\n",
    "        return 2\n",
    "\n",
    "    dialogue_in_data = data_dict[dialogue['id']]\n",
    "    utt = dialogue['dialogue'][turn_idx][role]\n",
    "    transcript = utt['transcript']\n",
    "    if dialogue['id'] == '4131' and turn_idx == 1:\n",
    "        evidences = {}\n",
    "    elif dialogue['id'] == '4131' and turn_idx > 1:\n",
    "        utt_in_data = dialogue_in_data['dialogue'][turn_idx - 1][role]\n",
    "        evidences = {slot_name.lower(): utt_in_data['slots']['fixed'][slot_name].get('evidence', None) for slot_name in utt_in_data['slots']['fixed']}\n",
    "    elif dialogue['id'] == '4154' and turn_idx == 7:\n",
    "        evidences = {}\n",
    "    elif dialogue['id'] == '4155' and turn_idx == 9:\n",
    "        evidences = {}\n",
    "    else:\n",
    "        try:\n",
    "            utt_in_data = dialogue_in_data['dialogue'][turn_idx][role]\n",
    "        except:\n",
    "            print(dialogue['id'])\n",
    "        utt_in_data = dialogue_in_data['dialogue'][turn_idx][role]\n",
    "        evidences = {slot_name.lower(): utt_in_data['slots']['fixed'][slot_name].get('evidence', None) for slot_name in utt_in_data['slots']['fixed']}\n",
    "    slot_acts = utt[turn_label_key.get(role, 'slot-action-mapping')].items()\n",
    "    slot_acts = sorted(slot_acts, key=sort_slot)\n",
    "    for slot, act in slot_acts:\n",
    "        transcript = delex_slot(transcript, slot, exclude_slots=exclude_slots, evidences=evidences)\n",
    "    return transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_token = '<|context|>'\n",
    "ectx_token = '<|endofcontext|>'\n",
    "bst_token = '<|belief|>'\n",
    "ebst_token = '<|endofbelief|>'\n",
    "act_token = '<|action|>'\n",
    "eact_token = '<|endofaction|>'\n",
    "rsp_token = '<|response|>'\n",
    "ersp_token = '<|endofresponse|>'\n",
    "\n",
    "sys_token = '<|system|>'\n",
    "usr_token = '<|user|>'\n",
    "img_token = '<|image|>'\n",
    "imgsrc_token = '<|imagesource|>'\n",
    "\n",
    "role2token = {\n",
    "    'agent': sys_token,\n",
    "    'user': usr_token\n",
    "}\n",
    "\n",
    "multi_space_matcher = re.compile('\\s{2,}')\n",
    "\n",
    "all_slot_names = {\"drinks\", \"music\", \"reservations\", \"dining options\", \"venueaddress\", \"menus\", \"outdoor seating\",\n",
    "                  \"venueneigh\", \"wheelchair accessible\", \"smoking\", \"parking\", \"venuescore\",\n",
    "                  \"restroom\", \"venuename\", \"price\", \"telephone\", \"credit cards\", \"wi-fi\", \"open span\", \"img_gt\"}\n",
    "\n",
    "def clean(text):\n",
    "    # Remove duplicated spaces\n",
    "    text = multi_space_matcher.sub(r' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def make_sample(dialogue,\n",
    "                turn_idx,\n",
    "                history_length=1,\n",
    "                with_context=True,\n",
    "                with_images=True,\n",
    "                with_belief=True,\n",
    "                with_action=True,\n",
    "                with_response=True,\n",
    "                delex=False,\n",
    "                sort_slots=True,\n",
    "                sort_func=None,\n",
    "                with_slot_name=True,\n",
    "                no_repetition=False,\n",
    "                accumulate_all_slots=False,\n",
    "                strict_slot_merge=False):\n",
    "    ret = []\n",
    "\n",
    "    if with_context:\n",
    "        ret.append(ctx_token)\n",
    "        ctx = make_context(dialogue, (turn_idx - history_length) if history_length > -1 else 0, turn_idx, with_images=with_images)\n",
    "        if ctx:\n",
    "            ret.append(ctx)\n",
    "        ret.append(ectx_token)\n",
    "\n",
    "    if with_belief:\n",
    "        ret.append(bst_token)\n",
    "        if accumulate_all_slots:\n",
    "            bst = []\n",
    "            for i in reversed(range(0, turn_idx)):\n",
    "                bst.append(make_bstate(dialogue['dialogue'][i]['bstate'], sort_slots=sort_slots, sort_func=sort_func))\n",
    "            bst = merge_bstate(bst, sort_slots=sort_slots, sort_func=sort_func, strict=strict_slot_merge)\n",
    "        else:\n",
    "            bst = make_bstate(dialogue['dialogue'][turn_idx - 1]['bstate'], sort_slots=sort_slots, sort_func=sort_func) if turn_idx > 0 else ''\n",
    "        if bst:\n",
    "            ret.append(bst)\n",
    "        ret.append(ebst_token)\n",
    "\n",
    "    if with_action:\n",
    "        ret.append(act_token)\n",
    "        act = make_bstate(dialogue['dialogue'][turn_idx]['agent']['dialog_act'], delex=False, sort_slots=sort_slots, sort_func=sort_func, with_slot_name=with_slot_name, no_repetition=no_repetition)\n",
    "        if act:\n",
    "            ret.append(act)\n",
    "        ret.append(eact_token)\n",
    "\n",
    "    if with_response:\n",
    "        ret.append(rsp_token)\n",
    "        rsp = make_context(dialogue, turn_idx, turn_idx + 1, roles=['agent'], with_images=with_images, delex=delex)\n",
    "        if rsp:\n",
    "            ret.append(rsp)\n",
    "        ret.append(ersp_token)\n",
    "    return ' '.join(ret).strip()\n",
    "\n",
    "def merge_bstate(bstates_reversed, sort_slots=True, sort_func=None, strict=False):\n",
    "    curr_slot_names = set()\n",
    "    merged = []\n",
    "    for bstate in bstates_reversed:\n",
    "        if bstate:\n",
    "            slot_texts = bstate.split('; ')\n",
    "            for slot_text in slot_texts:\n",
    "                found = False\n",
    "                for slot_name in all_slot_names:\n",
    "                    if slot_text.startswith(slot_name):\n",
    "                        found = True\n",
    "                        if not strict:\n",
    "                            curr_slot_names = curr_slot_names.difference(['open span', 'img_gt'])\n",
    "                        if slot_name not in curr_slot_names:\n",
    "                            curr_slot_names.add(slot_name)\n",
    "                            if slot_text not in merged:\n",
    "                                merged.append(slot_text)\n",
    "                if found == False:\n",
    "                    print(f'1111{slot_texts}1111')\n",
    "                    print(f'1111{slot_text}1111')\n",
    "                    raise Exception()\n",
    "    if sort_slots:\n",
    "        if sort_func is None:\n",
    "            merged.sort()\n",
    "        else:\n",
    "            merged.sort(key=lambda x: sort_func(x))\n",
    "    return '; '.join(merged)\n",
    "\n",
    "def make_slot_comps(name, value, act, delex=False, with_slot_name=True):\n",
    "    slot_comps = [name, value, act]\n",
    "    if delex:\n",
    "        slot_comps[1] = None\n",
    "    if not with_slot_name:\n",
    "        slot_comps[0] = None\n",
    "    return [(x.strip() if x is not None else '') for x in slot_comps]\n",
    "\n",
    "def make_bstate(bstate, with_images=True, delex=False, sort_slots=True, sort_func=None, with_slot_name=True, no_repetition=False):\n",
    "    all_slots = []\n",
    "    for slot, act in bstate.items():\n",
    "        slot = slot.replace('：', ':').replace('；', ':').replace(':', ': ').replace('  ', ' ')\n",
    "        name, value = extract_slot(slot)\n",
    "        if name in wrong_slots:\n",
    "            continue\n",
    "        if with_images or name != 'img_gts':\n",
    "            if name == 'img_gts':\n",
    "                name = 'img_gt'\n",
    "                for v in value.split(', '):\n",
    "                    all_slots.append(make_slot_comps(name, v, act, delex=delex, with_slot_name=with_slot_name))\n",
    "            else:\n",
    "                all_slots.append(make_slot_comps(name, value, act, delex=delex, with_slot_name=with_slot_name))\n",
    "    if sort_slots:\n",
    "        if sort_func is None:\n",
    "            all_slots.sort()\n",
    "        else:\n",
    "            all_slots.sort(key=lambda x: sort_func(x))\n",
    "    ret = [' '.join(x) for x in all_slots]\n",
    "    if no_repetition:\n",
    "        ret_set = set()\n",
    "        new_ret = []\n",
    "        for r in ret:\n",
    "            if r not in ret_set:\n",
    "                ret_set.add(r)\n",
    "                new_ret.append(r)\n",
    "        ret = new_ret\n",
    "    return clean('; '.join(ret))\n",
    "\n",
    "def make_context(dialogue, lower, upper, reverse=False, roles=('agent', 'user'), with_images=True, delex=False):\n",
    "    r = range(max(0, lower), min(len(dialogue['dialogue']), upper))\n",
    "    if reverse:\n",
    "        r = reverse(r)\n",
    "    ctx = []\n",
    "    for i in r:\n",
    "        for role in roles:\n",
    "            role_token = role2token[role]\n",
    "            if delex:\n",
    "                transcript = do_delex(dialogue, i, role=role, exclude_slots={'open span', 'img_gts', 'openspan', 'open psan', 'opne span', 'open open', 'opan span', 'open sapn', 'delivery', 'open span:', 'oprn span', 'openn span', 'open spicy', 'opens span', 'open spam', 'oepn span'})\n",
    "            else:\n",
    "                transcript = dialogue['dialogue'][i][role]['transcript']\n",
    "            images = ''\n",
    "            image_sources = ''\n",
    "            if with_images:\n",
    "                turn_label = dialogue['dialogue'][i][role][turn_label_key.get(role, 'slot-action-mapping')]\n",
    "                for slot, act in turn_label.items():\n",
    "                    name, value = extract_slot(slot)\n",
    "                    if name in wrong_slots:\n",
    "                        continue\n",
    "                    if name == 'img_gts':\n",
    "                        images = value\n",
    "                        image_sources = ', '.join(dialogue['dialogue'][i][role]['imgs'])\n",
    "                        break\n",
    "            if transcript or images:\n",
    "                ctx.append(role_token)\n",
    "                if transcript:\n",
    "                    ctx.append(transcript)\n",
    "                if images:\n",
    "                    ctx.append(img_token)\n",
    "                    ctx.append(images)\n",
    "                if image_sources:\n",
    "                    ctx.append(imgsrc_token)\n",
    "                    ctx.append(image_sources)\n",
    "    return clean(' '.join(ctx).replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/data_split.json...\n",
      "Loaded ../dataset/data_split.json to <class 'dict'> object\n",
      "train: 3500 dialogues\n",
      "val: 606 dialogues\n",
      "test: 1000 dialogues\n"
     ]
    }
   ],
   "source": [
    "splits = load(path + 'data_split.json')\n",
    "for split_name, split in splits.items():\n",
    "    print(f'{split_name}: {len(split)} dialogues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def prepare_path(path):\n",
    "    folder, file = os.path.split(path)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\n",
    "input_formats = {\n",
    "    'dialogpt': {\n",
    "        'history_length': -1,\n",
    "        'with_context': True,\n",
    "        'with_images': True,\n",
    "        'with_belief': False,\n",
    "        'with_action': False,\n",
    "        'with_response': True,\n",
    "        'delex': False,\n",
    "        'sort_slots': True,\n",
    "        'sort_func': None,\n",
    "        'with_slot_name': True,\n",
    "        'no_repetition': False,\n",
    "        'accumulate_all_slots': False,\n",
    "        'strict_slot_merge': False\n",
    "    },\n",
    "    'simpletod': {\n",
    "        'history_length': 4,\n",
    "        'with_context': True,\n",
    "        'with_images': False,\n",
    "        'with_belief': True,\n",
    "        'with_action': True,\n",
    "        'with_response': True,\n",
    "        'delex': True,\n",
    "        'sort_slots': True,\n",
    "        'sort_func': None,\n",
    "        'with_slot_name': True,\n",
    "        'no_repetition': False,\n",
    "        'accumulate_all_slots': False,\n",
    "        'strict_slot_merge': False\n",
    "    },\n",
    "    'simpletod_keep_slots': {\n",
    "        'history_length': -1,\n",
    "        'with_context': True,\n",
    "        'with_images': False,\n",
    "        'with_belief': True,\n",
    "        'with_action': True,\n",
    "        'with_response': True,\n",
    "        'delex': True,\n",
    "        'sort_slots': True,\n",
    "        'sort_func': None,\n",
    "        'with_slot_name': True,\n",
    "        'no_repetition': False,\n",
    "        'accumulate_all_slots': True,\n",
    "        'strict_slot_merge': False\n",
    "    }\n",
    "}\n",
    "\n",
    "output_format = \"simpletod\"\n",
    "\n",
    "for split_name, split in splits.items():\n",
    "    output = f'resources/{split_name}.{output_format}'\n",
    "    prepare_path(output)\n",
    "    with open(output, 'w+') as f:\n",
    "        for id_ in split:\n",
    "            dialogue = dialogues[id_]\n",
    "            for i in range(1, len(dialogue['dialogue'])):\n",
    "                sample = make_sample(dialogue, i, **input_formats[output_format])\n",
    "                f.write(f'{sample}\\n')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
